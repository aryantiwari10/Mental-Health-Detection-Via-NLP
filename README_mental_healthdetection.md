# ğŸ§  Mental Health Detection via NLP on Social Media

This project aims to detect potential **suicidal tendencies** in users based on their **social media posts**, using **Natural Language Processing (NLP)** and machine learning techniques.

We train and evaluate multiple models including **Logistic Regression, Random Forest, and XGBoost**, leveraging **TF-IDF** for feature extraction and **SMOTE** for handling class imbalance.

---

## ğŸ” Problem Statement

With the rise in mental health issues globally, early detection of suicidal behavior can save lives. This project focuses on **binary classification**:  
> ğŸ”¹ `suicide` vs. `non-suicide` based on the textual content of social media posts.

---

## ğŸ—ƒï¸ Dataset

- **Source**: Reddit `SuicideWatch` posts  
- **File**: `Suicide_Detection.csv`  
- **Columns**:
  - `text` â€“ User's post content
  - `class` â€“ Label (`suicide` or `non-suicide`)

---

## ğŸ“Š Project Workflow

### 1. ğŸ“¥ Data Loading
- Read CSV using pandas
- Checked for nulls and basic info

### 2. ğŸ§¼ Preprocessing
- Lowercasing, punctuation & stopword removal
- Tokenization and lemmatization
- Label encoding (`suicide` = 1, `non-suicide` = 0)

### 3. ğŸ“ˆ EDA (Exploratory Data Analysis)
- Class distribution visualization
- Word cloud generation
- Term frequency analysis

### 4. ğŸ§ª Feature Engineering
- Applied **TF-IDF Vectorization**
- Used unigrams & bigrams with max features

### 5. ğŸ§  Model Building
- **Logistic Regression**
- **Random Forest**
- **XGBoost Classifier**

All models were trained and tested on **80-20 train-test split**.

### 6. âš–ï¸ Handling Class Imbalance
- Applied **SMOTE (Synthetic Minority Oversampling Technique)**
- Balanced minority class (`suicide`) during training

### 7. ğŸ§¾ Evaluation Metrics
- **Confusion Matrix**
- **Classification Report**
  - Precision
  - Recall (critical for suicide detection)
  - F1-Score
- Visualizations of results (heatmaps, bar charts)

---

## ğŸ† Results

| Model               | Precision | Recall | F1-Score |
|--------------------|-----------|--------|----------|
| Logistic Regression| 0.92      | 0.88   | 0.90     |
| Random Forest       | 0.95      | 0.91   | 0.93     |
| XGBoost             | 0.96      | 0.94   | 0.95     |

> ğŸ“Œ **XGBoost** performed best in terms of overall precision, recall, and F1-score.

---

## âš™ï¸ Tech Stack

- ğŸ Python (Pandas, NumPy)
- ğŸ§  Scikit-learn, XGBoost
- ğŸ“Š Matplotlib, Seaborn, WordCloud
- ğŸ—£ï¸ NLTK & spaCy (for NLP)
- ğŸ§ª SMOTE (via imbalanced-learn)

---

## â–¶ï¸ How to Run

1. Clone this repo
2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
3. Run the notebook:
   ```bash
   jupyter notebook mental-health-detection-via-nlp-on-social-media.ipynb
   ```

---

## ğŸ’¡ Key Insights

- **Text-based features** (TF-IDF) work well with traditional ML models.
- **SMOTE** significantly improved model recall, especially for the suicidal class.
- **XGBoost** yielded the best balance of precision and recall.

---

## ğŸš€ Future Improvements

- Deploy as a web app (e.g., using Streamlit)
- Use BERT or other transformer models for improved accuracy
- Fine-tune threshold for maximizing recall on the `suicide` class
- Build real-time monitoring dashboard (for mental health professionals)

---

## ğŸ“š References

- Reddit SuicideWatch Dataset
- [imbalanced-learn](https://imbalanced-learn.org/)
- [scikit-learn documentation](https://scikit-learn.org/stable/)